{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBS data for whole NL\n",
    "- Need to:\n",
    "    - Clean for only necessary attributes (columns)\n",
    "    - find a way to filter for the city data (extents?) from CityPy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import folium\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cbs(cbs_data):\n",
    "    # load cbs data\n",
    "    cbs = gpd.read_file(cbs_data)\n",
    "    return cbs\n",
    "\n",
    "data1 = \"../data/cbs/cbs_vk500_2023_v1.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check layers in gpkg\n",
    "layers = gpd.list_layers(data1)\n",
    "layers\n",
    "\n",
    "print(f\"There is {len(layers)} layer(s) in the gpkg file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cbs.gpkg\n",
    "cbs_gdf = load_cbs(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the basics\n",
    "cbs_gdf.shape\n",
    "\n",
    "print(f\"This cbs file has {cbs_gdf.shape[0]} rows and {cbs_gdf.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_gdf.columns\n",
    "\n",
    "print(f\"This cbs file has the following columns: {cbs_gdf.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_gdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_gdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_gdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cbs_gdf.columns:\n",
    "    null_count = cbs_gdf[col].isnull().sum()\n",
    "    if null_count > 0:\n",
    "        print(f\"Column {col} has {null_count} null values.\")\n",
    "\n",
    "\"\"\" TODO: Can't make a quick decision to remove all rows with null values.\n",
    "The cells would mostly be in inhabited areas. Need to check first. But how? \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TODO:\n",
    "- load .csv\n",
    "- check overlapping data with the gpd file\n",
    "- create a data inventory of what to use and what not to use\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows that have at least (num_cols - 5) non-null values\n",
    "cbs_clean = cbs_gdf.dropna(thresh=cbs_gdf.shape[1] - 5)\n",
    "\n",
    "# save geom as wkt\n",
    "out_csv = \"../data/cbs/cbs_gdf_clean.csv\"  \n",
    "Path(out_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cbs_clean.assign(wkt=cbs_clean.geometry.apply(lambda g: g.wkt if g is not None else None)) \\\n",
    "         .drop(columns=\"geometry\") \\\n",
    "         .to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"Saved: {out_csv} (rows kept: {len(cbs_clean)} of {len(cbs_gdf)})\")\n",
    "cbs_clean.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2023 = pd.read_csv(\"../data/cbs/HH_500m_grid_2023.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This csv file has {csv_2023.shape[0]} rows and {csv_2023.shape[1]} columns.\")\n",
    "print(f\"This csv file has {len(csv_2023.columns.tolist())} following columns: {csv_2023.columns.tolist()}\")\n",
    "csv_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2023.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2023.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_2023.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs_clean.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "from shapely.geometry.base import BaseGeometry\n",
    "import geopandas as gpd\n",
    "\n",
    "def to_geom(val):\n",
    "    if isinstance(val, BaseGeometry):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        return wkt.loads(val)\n",
    "    return None\n",
    "\n",
    "cbs_clean[\"geometry\"] = cbs_clean[\"geometry\"].apply(to_geom)\n",
    "left_key = \"VRLVIERKANT500M\" # in csv_2023\n",
    "right_key = \"crs28992res500m\" # in cbs_clean\n",
    "geometry_lookup = cbs_clean[[right_key, \"geometry\"]].rename(columns={right_key: left_key})\n",
    "merged = pd.merge(csv_2023, geometry_lookup, on=left_key, how=\"left\")\n",
    "gdf = gpd.GeoDataFrame(merged, geometry=\"geometry\", crs = \"EPSG:28992\")\n",
    "gdf.to_file(\"../data/cbs/cbs_gdf_clean.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(cbs_clean.columns.tolist())[:20])  # peek\n",
    "[name for name in cbs_clean.columns if \"vierkant\" in name.lower() or \"500\" in name.lower() or \"grid\" in name.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(\"../data/cbs/cbs_gdf_clean.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-Cyw0LxUp-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
